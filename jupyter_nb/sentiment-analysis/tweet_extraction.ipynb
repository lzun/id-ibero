{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tweet_extraction.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "RuVbnXSM_z6m"
      },
      "source": [
        "import json\n",
        "import pickle\n",
        "import csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rx-L0pxKBn6n"
      },
      "source": [
        "Algunas varibales globales que envuelven parametros de los tweets minados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxYmr_Q6BaeO"
      },
      "source": [
        "tweet_params = ['author_id', 'text', 'public_metrics', 'id', 'created_at']\n",
        "public_metrics = ['retweet_count', 'reply_count', 'like_count', 'quote_count']\n",
        "header = ['author_id', 'text', 'retweet_count', 'reply_count', 'like_count', 'quote_count', 'id', 'created_at']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBgtFPyHCuI6"
      },
      "source": [
        "def extract_fields(fileName):\n",
        "\ttwt_dicc = {}\n",
        "\twith open(fileName, 'r') as f:\n",
        "\t\tfor line in f:\n",
        "\t\t\taux = json.loads(line)\n",
        "\t\t\ttwt_dicc[aux['id']] = {}\n",
        "\t\t\tfor item in tweet_params:\n",
        "\t\t\t\tif (item=='public_metrics'):\n",
        "\t\t\t\t\tfor j in public_metrics:\n",
        "\t\t\t\t\t\ttwt_dicc[aux['id']][j] = aux[item][j]\n",
        "\t\t\t\telse:\n",
        "\t\t\t\t\ttwt_dicc[aux['id']][item] = aux[item]\n",
        "\treturn twt_dicc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZOYmXucLI9M3"
      },
      "source": [
        "def build_spreadsheet(file_name, tweets):\n",
        "\twith open(file_name, 'w') as csv_file:\n",
        "\t\twriter = csv.DictWriter(csv_file, fieldnames = header, delimiter =';')\n",
        "\t\twriter.writeheader()\n",
        "\t\tfor key,value in tweets.items():\n",
        "\t\t\tstring = value['text'].replace('\\\\xe1', 'á')\n",
        "\t\t\tstring = string.replace('\\t',' ')\n",
        "\t\t\tstring = string.replace('\\\\xe9', 'é')\n",
        "\t\t\tstring = string.replace('\\\\xed', 'í')\n",
        "\t\t\tstring = string.replace('\\\\xf3', 'ó')\n",
        "\t\t\tstring = string.replace('\\\\xfa', 'ú')\n",
        "\t\t\tstring = string.replace('\\\\xf1', 'ñ')\n",
        "\t\t\tstring = string.replace('\\\\xa1', '!')\n",
        "\t\t\tstring = string.replace('\\n', ' ')\n",
        "\t\t\tstring = string.replace('\\\\u2026', '...')\n",
        "\t\t\tvalue['text'] = string\n",
        "\t\t\twriter.writerow(value)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "En la variable `file_name` pongan el nombre del archivo donde guardaron los tweets. En la variable `csv_file_name` nombren el archivo donde van a crear el archivo csv con los tweets extraidos:"
      ],
      "metadata": {
        "id": "aEROm3g5Y8RD"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jr8ZCDkpDrzJ"
      },
      "source": [
        "# nombre del archivo donde se guardan los datos extraidos de twiiter\n",
        "file_name = '' \n",
        "\n",
        "# nombre del archivo csv donde se extrae los tweets para su anotacion\n",
        "csv_file_name = ''\n",
        "\n",
        "# extraer los campos en cada tweet\n",
        "tweets  = extract_fields(file_name)\n",
        "\n",
        "# construir los archivos csv\n",
        "build_spreadsheet(csv_file_name,tweets)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}